apiVersion: sparkoperator.k8s.io/v1beta2
kind: ScheduledSparkApplication
metadata:
  name: srvc-stats
  namespace: spark
spec:
  schedule: "@every 2m"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 1
  template:
    type: Scala
    mode: cluster
    sparkVersion: 3.5.5
    image: spark:3.5.5
    imagePullPolicy: IfNotPresent
    mainClass: org.apache.spark.examples.SparkPi
    mainApplicationFile: local:///opt/spark/examples/jars/spark-examples.jar
    restartPolicy:
      type: Never
    sparkConf:
      "spark.eventLog.enabled": "true"
      "spark.eventLog.dir": "file:///tmp/spark-events"
      "spark.history.fs.logDirectory": "file:///tmp/spark-events"
      "spark.eventLog.compress": "true"
      "spark.eventLog.rolling.enabled": "true"
      "spark.eventLog.rolling.maxFileSize": "128m"
    driver:
      cores: 1
      memory: 512m
      serviceAccount: spark-operator-spark
      volumeMounts:
        - name: spark-events
          mountPath: /tmp/spark-events
      securityContext:
        runAsUser: 185
        runAsGroup: 185
        runAsNonRoot: true
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
        seccompProfile:
          type: RuntimeDefault
    executor:
      instances: 1
      cores: 1
      memory: 512m
      volumeMounts:
        - name: spark-events
          mountPath: /tmp/spark-events
      securityContext:
        runAsUser: 185
        runAsGroup: 185
        runAsNonRoot: true
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
        seccompProfile:
          type: RuntimeDefault
    volumes:
      - name: spark-events
        persistentVolumeClaim:
          claimName: spark-events-pvc
